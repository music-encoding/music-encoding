<?xml version="1.0" encoding="UTF-8"?>
<!-- 
  NOTICE: Copyright (c) by the Music Encoding Initiative (MEI) Board (formerly known as "MEI Council").

  Licensed under the Educational Community License, Version 2.0 (the "License"); you may
  not use this file except in compliance with the License. You may obtain a copy of the License
  at https://opensource.org/licenses/ECL-2.0.
  
  Unless required by applicable law or agreed to in writing, software distributed under the
  License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS
  OF ANY KIND, either express or implied. See the License for the specific language
  governing permissions and limitations under the License.
  
  This is a derivative work based on earlier versions of the schema © 2001-2006 Perry Roland
  and the Rector and Visitors of the University of Virginia; licensed under the Educational
  Community License version 1.0.
  
  CONTACT: info@music-encoding.org
-->
<?xml-model href="../validation/mei_odds.rng" type="application/xml" schematypens="http://purl.oclc.org/dsdl/schematron"?>
<?xml-model href="../validation/mei_odds.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?>
<TEI xmlns:rng="http://relaxng.org/ns/structure/1.0"
   xmlns:sch="http://purl.oclc.org/dsdl/schematron" xmlns="http://www.tei-c.org/ns/1.0"
   version="5.0" rend="book" xml:lang="en">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <title level="s">The Music Encoding Initiative Guidelines</title>
            <title level="a">Introduction to MEI</title>
            <respStmt>
               <resp>Edited by</resp>
               <name role="edt">Johannes Kepper</name>
               <note>The editors listed here are responsible for the contents of this very chapter of the MEI Guidelines.</note>
            </respStmt>
            <respStmt>
               <resp>With contributions by</resp>
               <!--TODO: To be filled automatically via GitHub API-->
               <name ref="https://api.github.com/users/bwbohl">Benjamin W. Bohl</name>
               <name ref="https://api.github.com/users/BruxDDay">BruxDDay</name>
               <name ref="https://api.github.com/users/ndubo">Norbert Dubowy</name>
               <name ref="https://api.github.com/users/fujinaga">Ichiro Fujinaga</name>
               <name ref="https://api.github.com/users/axgeertinger">Axel Geertinger</name>
               <name ref="https://api.github.com/users/ahankinson">Andrew Hankinson</name>
               <name ref="https://api.github.com/users/irmlindcapelle">irmlindcapelle</name>
               <name ref="https://api.github.com/users/frakel">franz kelnreiter</name>
               <name ref="https://api.github.com/users/kepper">kepper</name>
               <name ref="https://api.github.com/users/zolaemil">Zoltan Komives</name>
               <name ref="https://api.github.com/users/DDMAL-LabManager">DDMAL LabManager</name>
               <name ref="https://api.github.com/users/uliska">Urs Liska</name>
               <name ref="https://api.github.com/users/elsinhadl">Elsa De Luca</name>
               <name ref="https://api.github.com/users/napulen">Néstor Nápoles López</name>
               <name ref="https://api.github.com/users/MajaHartwig">MajaHartwig</name>
               <name ref="https://api.github.com/users/musicEnfanthen">Stefan Münnich</name>
               <name ref="https://api.github.com/users/apacha">Alexander Pacha</name>
               <name ref="https://api.github.com/users/pe-ro">pe-ro</name>
               <name ref="https://api.github.com/users/lpugin">Laurent Pugin</name>
               <name ref="https://api.github.com/users/JRegimbal">Juliette Regimbal</name>
               <name ref="https://api.github.com/users/rettinghaus">Klaus Rettinghaus</name>
               <name ref="https://api.github.com/users/aseipelt">Agnes Seipelt</name>
               <name ref="https://api.github.com/users/martha-thomae">Martha E. Thomae</name>
               <name ref="https://api.github.com/users/raffazizzi">Raffaele Viglianti</name>
               <name ref="https://api.github.com/users/vigliensoni">Gabriel Vigliensoni</name>
               <name ref="https://api.github.com/users/th-we">Thomas Weber</name>
               <name ref="https://api.github.com/users/musicog">David M. Weigl</name>
            </respStmt>
         </titleStmt>
         <publicationStmt>
            <distributor>Music Encoding Initiative (MEI) Board</distributor>
            <availability>
               <p>
                  <hi>Music Encoding Initiative (MEI)</hi>
               </p>
               <p>NOTICE: Copyright (c) by the Music Encoding Initiative (MEI) Board (formerly known as "MEI Council").</p>
               <p>Licensed under the Educational Community License, Version 2.0 (the "License"); you
                  may not use this file except in compliance with the License. You may obtain a copy
                  of the License at <ref target="http://opensource.org/licenses/ECL-2.0"
                     >http://opensource.org/licenses/ECL-2.0</ref>.</p>
               <p>Unless required by applicable law or agreed to in writing, software distributed
                  under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR
                  CONDITIONS OF ANY KIND, either express or implied. See the License for the
                  specific language governing permissions and limitations under the License.</p>
               <p>This is a derivative work based on earlier versions of the schema copyright (c)
                  2001-2006 Perry Roland and the Rector and Visitors of the University of Virginia;
                  licensed under the Educational Community License version 1.0.</p>
               <p>CONTACT: contact@music-encoding.org </p>
            </availability>
         </publicationStmt>
         <sourceDesc>
            <p>Born digital: No previous source exists.</p>
        </sourceDesc>
      </fileDesc>
   </teiHeader>
   <text>
      <body>
         <div xml:id="introduction" type="div1">
            <head>Introduction to MEI</head>
            <p>Welcome to the MEI Guidelines. They provide documentation for the Music Encoding
               Initiative’s framework for describing music notation documents. This includes both a
               technical specification of the XML-based implementation of MEI and an explanatory
               description of its concepts.</p>
            <div xml:id="about" type="div2">
               <head>About these Guidelines</head>
               <p>The MEI Guidelines are intended to serve as a reference tool for music encoders.
               Through the use of natural-language definitions and examples, this documentation
               assists users of MEI in achieving effective and consistent markup. Despite
               translating XML and RNG terminology and concepts into more accessible language, it is
               still a technical one that presupposes a minimal understanding of XML and music
               notation. Novice encoders may want to start their MEI experience by doing an <ref
                  target="https://music-encoding.org/resources/tutorials.html">introductory
                  tutorial</ref> first. These Guidelines will provide recommendations and arguments
               for encoding different types of music notation for a variety of purposes. While the
               specification of the framework is complete, the description is not necessarily
               complete. MEI is used in various contexts, and not every use-case may be fully
               reflected in these Guidelines. However, MEI is a community effort, so feedback and
               suggestions for improvement are highly welcome. Several starting points to get in
               touch with the MEI community can be found on the <ref
                  target="https://music-encoding.org/community/community-contacts.html">MEI
                  website</ref>.</p>
            <p>These Guidelines make use of real-world examples to illustrate appropriate encoding
               concepts. We consider the use of such images as fair use. Contributors to these
               Guidelines are requested to given proper reference to the libraries holding the
               material used here. They're also asked to be aware of potential copyright
               infringements and avoid respective material, or replace it with hand-drawn, made-up
               examples. If you find material that possibly offends copyright, please <ref
                  target="mailto:info@music-encoding.org">get in touch</ref> with us, and we will
               take it down.</p>
               <div xml:id="acknowledgments" type="div3">
                  <head>Acknowledgments</head>
                  <p>Many institutions and individuals assisted in the preparation of these
                     Guidelines and in the overall development of the Music Encoding Initiative
                     framework and community.</p>
                  <p>Grateful acknowledgment is given to the following institutions for their
                     generous contributions: the Akademie der Wissenschaften und der Literatur (AdW)
                     in Mainz for serving as hosting institution for the MEI Community, and the
                     National Endowment for the Humanities (NEH) and the Deutsche
                     Forschungsgemeinschaft (DFG) for their joint financial support of the MEI
                     project in its early stages. We thank several institutions that hosted Music
                     Encoding Conferences or other MEI-related meetings in the past: The AdW Mainz,
                     the University of Virginia Library, the Biblioteca Umanistica of the
                     Università degli Studi Firenze, McGill University Montréal, the Centre
                     d’études supérieures de la Renaissance Tours, the Maryland Institute for
                     Technology in the Humanities (MITH) in College Park, the Oxford e-Research
                     Centre, the Universität Paderborn and the Österreichische Akademie der
                     Wissenschaften Wien in conjunction with the Universität Wien and the Mozarteum
                     Salzburg. We also thank all other institutions that allow their researchers to
                     invest time into both the community and the encoding framework. It is their
                     interest that makes MEI an incredible platform for interchange and scholarly
                     progress.</p>
                  <p>The Text Encoding Initiative is also owed a special debt of gratitude. In
                     addition to providing much of the inspiration for MEI, the TEI organization
                     supplied funding for the MEI Technical Group in its efforts to adopt ODD. The
                     editors of these Guidelines are grateful for those of the TEI, which provided a
                     stellar exemplar and from which we have borrowed shamelessly.</p>
                  <p>MEI has been a community-driven effort for more than a decade, and many
                     individuals have provided significant and much-appreciated commitments of time
                     and energy to the development of MEI: Nikolaos Beer; Vincent Besson; Benjamin
                     W. Bohl; Margrethe Bue; Donald Byrd; Irmlind Capelle; Tim Crawford; David A.
                     Day; Giuliano Di Bacco; Norbert Dubowy; Richard Freedman; Ichiro Fujinaga;
                     Andrew Hankinson; Maja Hartwig; Kristin Herold; Franz Kelnreiter; Johannes
                     Kepper; Robert Klugseder; Zoltán Kőmíves; David Lewis; Urs Liska; Elsa De Luca;
                     Erin Mayhood; Stefan Morent; Stefan Münnich; Markus Neuwirth; Kevin Page;
                     Daniel Pitti; Laurent Pugin; Klaus Rettinghaus; Kristina Richts; Daniel
                     Röwenstrunk; Perry Roland; Craig Sapp; Agnes Seipelt; Eleanor Selfridge-Field;
                     Christine Siegert; Peter Stadler; Axel Teich Geertinger; Martha Thomae; Joachim
                     Veit; Raffaele Viglianti; Thomas Weber; and Sonia Wronkowska.</p>
                  <p>Thanks to Bernhard R. Appel; Richard Chesser; Morgan Cundiff; J. Stephen
                     Downie; Oliver Huck; Fotis Jannidis; John Rink; Federica Riva; Frans Wiering
                     and Barbara Wiermann for providing expertise on a wide range of topics related
                     to music notation modelling.</p>
                  <p>Also thanks to Syd Bauman, Terry Catapano, and Sebastian Rahtz for their
                     invaluable problem-solving assistance during the development of the 2010 RNG
                     schema. Thanks to Sebastian Rahtz and James Cummings of the Text Encoding
                     Initiative (TEI) for their help with making ODD work with MEI, their assistance
                     in more closely aligning MEI and TEI, and their quick responses to questions
                     and Roma bug reports.</p>
                  <p>Finally, the members of the Music Encoding Initiative would like to thank Perry
                     Roland for his foresight, engagement and dedication in laying the foundations
                     of this initiative.</p>
               </div>
               <div xml:id="aboutVersion" type="div3">
                  <head>About version 5.0</head>
                  <p>Release 5.0 of MEI focuses primarily on the guidelines, development infrastructure, 
                     and consistency, with only limited changes to the specifications. Perhaps the most important 
                     additions are the introduction of the MEI Basic customization, and the availability 
                     of an auto-generated PDF version of the Guidelines (see below for more details on both).
                     The Release Managers for MEI 5.0 were the Technical Co-Chairs, Benjamin W. Bohl and Stefan
                     Münnich.
                  </p>
                  <div xml:id="meiBasic" type="div4">
                     <head>MEI Basic</head>
                     <p>As a framework to encode music, MEI offers extensive flexibility to encode music
                     documents of various kinds, and for a wide variety of uses. For scholarly research, 
                     this flexibility is necessary and is one of the greatest strengths of MEI. At the 
                     same time, we recognize that this flexibility presents challenges for broad adoption 
                     of MEI as a notation interchange format. For developers, providing "full" MEI support 
                     is a difficult and time-consuming chore, writing and supporting code for features 
                     which most of their users will not use. Accordingly, MEI has not seen a great deal of adoption 
                     by current score-writing applications.</p>
                     <p>This is addressed this with the release of MEI 5. We are now offering a new customization of MEI, 
                     <hi rend="italic">MEI Basic</hi>, that provides a simplified subset of the MEI framework that 
                     reflects the capabilities of most popular "Common Western Music Notation" score-writing 
                     applications currently in use.</p>
                     <p>In the full MEI schema there are often multiple ways to encode something. MEI Basic 
                     simplifies this by providing only one approach for each music feature, making it significantly
                     easier to provide full feature support in software. As noted, MEI Basic only supports 
                     Common Western Music Notation. Many of the more complex encoding mechanisms for
                     editorial and analytical workflows are also removed in MEI Basic. MEI Basic has a relatively 
                     small footprint of supported features, which may be expanded over time as more software 
                     applications adopt MEI and more use cases are identified. All MEI Basic files are 
                     valid MEI "full" files, meaning MEI Basic files may be expanded and upgraded to MEI "full",
                     adding more complex features and encoding mechanisms as required.</p>
                    <p>We hope that this customization facilitates more application adoption, data sharing between 
                      MEI projects, and conversion between MEI and other data formats.</p>
                  </div>
                  <div xml:id="pdfGuidelines" type="div4">
                     <head>Guidelines</head>
                     <p>With MEI 5, we re-introduce a PDF version of the MEI Guidelines. With a total
                     of more than 5,700 pages, this PDF clearly is not intended to be printed, but may 
                     serve as a single-file reference to the current release of MEI. The PDF is 
                     interactive, so may be offline with working links between sections. While the 
                     largest part of the PDF is taken up by the formal specification of the format, 
                     there are also more than 370 pages of prose documentation and examples of how to 
                     use the MEI framework for various purposes. The PDF therefore gives a good 
                     impression of the huge effort that went into the development of MEI.</p>
                     <p>The Guidelines have also had several notable contributions, led in large part 
                     by our Interest Groups. These contributions have sought to make some chapters more
                     clear and consistent, to help newcomers to MEI understand how MEI encoding may be
                     applied.</p>
                     <p>In total, we have over 40 contributors actively involved in 
                     the preparation of this release of MEI. Many of them are early-career researchers, 
                     investing significant time and effort into the MEI Framework. Due to the open 
                     nature of this community work, happening alongside conferences, workshops, and 
                     other meetings, others may not be listed properly because of rather informal, 
                     but no less important, contributions. Without the joint effort of all those involved, 
                     an undertaking like MEI would not be possible.</p>
                  </div>
                  <div xml:id="modelChanges" type="div4">
                     <head>Model changes in MEI</head>
                     <p>MEI 5 introduces five new elements: <gi scheme="MEI">plica</gi> and 
                     <gi scheme="MEI">stem</gi>, for the encoding of documents written in Mensural 
                     notation, and <gi scheme="MEI">divLine</gi> for Neumes documents. The new CMN 
                     element <gi scheme="MEI">repeatMark</gi> can be used to express repetition marks 
                     as a combination of text and symbols, and the added shared element 
                     <gi scheme="MEI">extData</gi> provides a container for non-MEI data formats. 
                     The release technically removes the &lt;fingerprint&gt; element, which has been 
                     deprecated for ten years. It also removes the elements &lt;pgHead2&gt; and 
                     &lt;pgFoot2&gt;, which are now superseded by the <att>func</att> attribute on 
                     <gi scheme="MEI">pgHead</gi> and <gi scheme="MEI">pgFoot</gi> respectively.</p>
                     <p>Most other changes affect more specific aspects in the model of MEI, usually 
                     expressed in attributes. These include the refinement of the encoding of key 
                     signatures, with <att>key.sig</att> moved to <att>keysig</att>, <att>keysig.show</att> moved to 
                     <att>keysig.visible</att>, and <att>keysig.showchange</att> and <att>sig.showchange</att> moved to 
                     <att>keysig.cancelaccid</att> and <att>cancelaccid</att> respectively. The <att>instr</att> 
                     attribute is removed from quiet events like <gi scheme="MEI">rest</gi>, 
                     <gi scheme="MEI">mRest</gi>, <gi scheme="MEI">mSpace</gi> and <gi scheme="MEI">multiRest</gi>, 
                     and the <att>visible</att> attribute is also removed from <gi scheme="MEI">mRest</gi>. 
                     Moreover, attributes <att>line.form</att> and <att>line.width</att> on the <gi scheme="MEI">arpeg</gi> 
                     element are aligned with other line-like elements as <att>lform</att> and 
                     <att>lwidth</att>. <att>text.dist</att> on <gi scheme="MEI">scoreDef</gi> and 
                     <gi scheme="MEI">staffDef</gi> is removed in favor of the newly added attributes 
                     <att>dir.dist</att>, <att>reh.dist</att> or <att>tempo.dist</att>. 
                     <att>meter.form</att>="invis" is updated to <att>meter.visible</att>="false", 
                     and the same change applies to <att>form</att>="invis" on meterSig, now replaced 
                     with <att>visible</att>="false". The text-rendition values of <val>letter-spacing</val> 
                     and <val>line-height</val> on <att>rend</att> are moved to separate attributes, that is, 
                     <att>rend</att>="letter-spacing(0.25) line-height(120%)" will be now 
                     <att>letterspacing</att>="0.25" <att>lineheight</att>="120%". Additionally, corrections 
                     are applied to specific attribute values, such as changing <val>Bagpipe</val> on
                     <att>midi.instrname</att> to <val>Bag_pipe</val> and replacing <val>dblwhole</val> 
                     on <att>head.mod</att> with <val>fences</val>. All changes can be traced in the 
                     detailed Release Notes auto-generated from the Pull Requests on GitHub. A larger 
                     group of changes affects the internal class structure of MEI only, where significant
                     effort went into improved consistency in naming things. While this set of changes 
                     does not affect end users of MEI during validation of files, they may have 
                     consequences for local customizations which reference classes not available anymore. 
                     If you have advanced local customizations based on MEI v4 or older releases, 
                     please check that the rules provided still work as expected under v5. A very helpful 
                     addition for this task may be the validation for MEI customizations, which is now 
                     available and used for all customizations officially provided by MEI.</p>
                  </div>
                  <div xml:id="infrastructuralChanges" type="div4">
                     <head>Infrastructural changes</head>
                     <p>A lot of effort went into updating the infrastructure for generating releases. These
                     changes are designed to help improve the development workflow of MEI, improving consistency
                     and oversight of changes as they are contributed to MEI. Our new setup is explained in 
                     great detail in <ref target="https://github.com/music-encoding/music-encoding/blob/dev/README.md">the project README file</ref>. 
                     We have also expanded our <ref target="https://github.com/music-encoding/music-encoding/blob/dev/CONTRIBUTING.md">Contribution Guidelines</ref> 
                     and other documentation files in the <ref target="https://github.com/music-encoding/music-encoding">music-encoding GitHub repository</ref>.</p>
                     <p>The MEI documentation and guidelines are now expressed in TEI ODD again, 
                     moving away from the MarkDown-based approach used in the preparation of 
                     MEI v4 documentation. This re-introduces greater compatibility with the TEI toolset. 
                     The source code for both the Guidelines and the Specification is now jointly 
                     contained in the <ref target="https://github.com/music-encoding/music-encoding">music-encoding GitHub repository</ref>, 
                     which simplifies validation across both parts of MEI. All assets – web 
                     documentation, PDF Guidelines, and schemata – are automatically generated from there. 
                     A multi-platform Docker image for running these processes locally is also provided
                     to help new developers with getting started in contributing to MEI.
                     Setting up these technical workflows has taken considerable effort, but should now 
                     simplify future development and releases considerably.</p>
                    <p>In addition to the main Music Encoding schema and Guidelines, we have also updated
                    our Sample Encodings and Encoding Tools repositories. Sample Encodings have been updated
                    to MEI 5.0, and several problems with encodings from older releases have been fixed. In the
                    Encoding Tools, several bugs were fixed with older upgrade XSLT scripts, and a new XSLT for
                    upgrading MEI 4 to MEI 5 was added.</p>
                    <p>To see all of the changes made for this revision, please visit our Git repositories:
                    <list rend="simple">
                      <item><ref target="https://github.com/music-encoding/music-encoding">https://github.com/music-encoding/music-encoding</ref></item>
                      <item><ref target="https://github.com/music-encoding/sample-encodings">https://github.com/music-encoding/sample-encodings</ref></item>
                      <item><ref target="https://github.com/music-encoding/encoding-tools">https://github.com/music-encoding/encoding-tools</ref></item>
                    </list>
                    </p>
                    <p>The editors wish to thank everyone who participated in this process. Of course, 
                    errors and omissions are the sole responsibility of the editors.</p>
                  </div>
               </div>
            </div>
            <div xml:id="designPrinciples" type="div2">
               <head>MEI Design Principles</head>
               <p>This section of the Guidelines defines principles and criteria for designing,
                  developing, and maintaining an XML-based encoding scheme for music notation
                  documents.</p>
               <div xml:id="definitionsAndParameters" type="div3">
                  <head>Definitions and Parameters</head>
                  <p>A music notation document is one that contains music notation; that is, any
                     one of a number of "visual analogues of musical sound, either as a record of
                     sound heard or imagined, or as a set of visual instructions for performers."
                     (Ian D. Bent, et al. "Notation." Grove Music Online. Oxford Music Online. 25
                     May 2010. <ref
                        target="http://www.oxfordmusiconline.com/subscriber/article/grove/music/20114"
                        >http://www.oxfordmusiconline.com/subscriber/article/grove/music/20114</ref>.)
                     However, MEI’s understanding is more inclusive than this restrictive
                     definition, <abbr>i.e.</abbr>, Braille certainly qualifies as music notation
                     documents.</p>
                  <p>The encoding scheme permits both the creation of new music notation
                     documents and the conversion of existing ones from print and other
                     electronic formats. However, conversion of existing documents may require
                     revisions in content or rearrangement of information.</p>
               </div>
               <div xml:id="generalPrinciples" type="div3">
                  <head>General Principles</head>
                  <p>MEI may be used to encode both primary sources of music notation, such as an
                     autograph or published score, and secondary sources, such as a scholarly
                     edition based on one or more primary sources. The format encompasses both
                     use cases, and the encoder must choose the elements and attributes most
                     appropriate in each case. These Guidelines aim to provide guidance on that
                     task.</p>
                  <p>As an encoded representation of one or more music notation documents, an MEI
                     file may be employed as a surrogate for the original materials.</p>
                  <p>Although the encoding scheme does not define or prescribe intellectual
                     content for music notation documents, it does define content designation and
                     is intended to be used with available data content standards. MEI identifies
                     the essential data elements within music notation documents and establishes
                     codes and conventions necessary for capturing and distinguishing information
                     within those elements for future action or manipulation. While there are a
                     few elements that ought to appear in any MEI document, various intellectual,
                     technical, and economic factors influence the level of detail of analysis
                     and encoding actually undertaken. Taking this into consideration, the
                     encoding scheme is designed with a minimum of required elements and allows
                     for progressively more detailed levels of description as desired.</p>
                  <p>The encoding scheme preserves and enhances the current functionality of
                     existing music notation documents. It permits identification of document
                     structures and content that support description, navigation, analysis, and
                     online and print presentation.</p>
                  <p>The encoding scheme is intended to facilitate interchange between notational
                     tools. It aims to assist in the creation of more effective and consistent
                     encoding, encourage the creation of cooperatively-created and widely
                     available databases of music notation documents, and permit the reuse of
                     encoded data for multiple output purposes. It will also ensure that
                     machine-readable music notation documents will outlive changing hardware and
                     software environments because they are based on a platform-independent
                     standard.</p>
               </div>
               <div xml:id="structuralFeatures" type="div3">
                  <head>Structural Features</head>
                  <p>The encoding scheme is based on eXtensible Markup Language (XML), a
                     text-based format for representing structured information. It is expressed
                     as a One Document Does-it-all (ODD) document. For more information on ODD, please refer to <ptr target="#meiCustomization"/>.</p>
                     <p>Related or complementary standards, such as the <ref target="http://www.tei-c.org/Guidelines/P5/">Text Encoding Initiative (TEI) Guidelines for Electronic Text Encoding and Interchange</ref>, <ref target="http://www.loc.gov/ead/">the Encoded Archival Description (EAD)</ref>, <ref target="http://www.loc.gov/marc/bibliographic/ecbdhome.html">MARC 21 Format for Bibliographic Data</ref>, existing notation encoding schemes, etc. have been consulted and employed as appropriate. For example, the data
                     model includes a header that is comparable to the TEI header, and TEI and
                     EAD naming conventions and tag structures have been used whenever feasible.
                     However, while some feature names are similar, or even the same, it is
                     important to recognize that MEI and TEI have different semantic scope.
                     Obviously, a note element in MEI does not carry the same meaning as the
                     element of the same name in TEI. Perhaps less obviously, a phrase in music
                     notation is unrelated to a textual phrase.</p>
                  <p>With respect to metadata, MEI recognizes the close relationship between the
                     metadata content found in the MEI header and that of catalog records,
                     authority records, and finding aids. Therefore MEI provides ways of
                     indicating in the encoding the corresponding fields of other metadata
                     standards.</p>
                  <p>To ensure broad international and multi-repertoire application of MEI,
                     existing musical terminology was used in building the data model where
                     practical. When appropriate, a more neutral terminology was used to
                     facilitate sharing of concepts and thus stressing the commonalities between
                     different repertoires. Finally, extensive use of attributes and
                     clearly-defined classification mechanisms in the schema permits the
                     refinement of element meanings within specific musical, geographic, or
                     temporal contexts.</p>
               </div>
               <div xml:id="controlAndMaintenance" type="div3">
                  <head>Control and Maintenance</head>
                  <p>The Music Encoding Initiative Community has given itself <ref
                        target="https://music-encoding.org/community/mei-by-laws.html"
                        >By-laws</ref>, which regulate all essential properties and procedures.
                     The community elects a <ref
                        target="https://music-encoding.org/community/mei-board.html">Board</ref>,
                     which in turn governs and represents the community. The Board consists of
                     nine elected members, with three seats standing for election for three year
                     terms each year. Everyone registered to the <ref
                        target="https://music-encoding.org/community/community-contacts.html"
                        >MEI-L</ref> mailing list is eligible to vote for the Board.</p>
                  <p>In addition to the Board, there is a <ref
                        target="https://music-encoding.org/community/technical-team.html"
                        >Technical Team</ref>, which is open for anyone interested to work on the
                     maintenance and improvement of MEI itself. The Technical team will assist
                     Interest Groups and other interested community members in an advisory
                     capacity on how to further develop MEI for both existing and new fields of
                     application.</p>
               </div>
            </div>
            <div xml:id="basicConcepts" type="div2">
               <head>Basic Concepts of MEI</head>
               <p>This chapter is intended to explain basic concepts of MEI, like events vs.
                  controlevents.</p>
               <div xml:id="musicalDomains" type="div3">
                  <head>Musical Domains</head>
                  <p>The term "music" has many different notions, ranging from audible sounds over
                     written performance instructions or transcriptions of such events to conceptual
                     rulesets that establish different theories of what music is, and what is
                     allowed in music. In 1965, Milton Babbitt distinguished between <hi
                        rend="italic">graphemic</hi>, <hi rend="italic">acoustic</hi> and <hi
                        rend="italic">auditory</hi> aspects of music (Babbitt, Milton: <hi
                        rend="italic">The Use of Computers in Musicological Research</hi>, in: <hi
                        rend="italic">Perspectives of New Music</hi> 3/2 (1965), p. 76).</p>
                  <p>Various music encoding formats took up this distinction, most notably SMDL, the
                        <hi rend="italic">Standard Music Description Language</hi> (ISO/IEC DIS
                     10743). While the format itself was hardly ever used for its impractical
                     implementation details, parts of its design certainly influenced the
                     development of other formats, including MEI. In a documentation draft (<ref
                        target="http://xml.coverpages.org/smdl10743-pdf.gz"
                        >http://xml.coverpages.org/smdl10743-pdf.gz, p.5</ref>), SMDL identifies
                     four different <hi rend="italic">musical domains</hi>:</p>
                  <list type="gloss">
                     <label>logical domain</label>
                     <item>The logical domain is the basic musical content – the essence from which
                        all performances and editions of the work are derived, including virtual
                        time values, nominal pitches, etc. The logical domain is describable as “the
                        composer’s intentions with respect to pitches, rhythms, harmonies, dynamics,
                        tempi, articulations, accents, etc.,” and it is the primary focus of SMDL.
                        It can also be described as “the abstract information common to both the
                        gestural and visual domains.” […]</item>
                     <label>gestural domain</label>
                     <item>The gestural domain is comprised of any number of performances, each of
                        which may specify how and when components of the logical domain is rendered
                        in a specific performance, including all the means whereby the performer
                        actually “expresses” (acoustically instantiates) the music (intonation,
                        agogic and dynamic stress, etc.). The gestural domain is perhaps most
                        succinctly described as “the information added by performers,” or “how the
                        music actually sounds during particular performances.” […]</item>
                     <label>visual domain</label>
                     <item>The visual domain is comprised of any number of scores, each of which
                        somehow specifies exactly how components of the logical domain is rendered
                        visually in some particular printable (and/or displayable) edition,
                        including such graphical details as symbology, symbol sets, fonts, page
                        layout, beaming conventions and exceptions, etc. The visual domain is
                        perhaps most succinctly described as “the information added by human
                        editors, engravers, and typesetters,” or “how the music actually looks in
                        some particular edition.” […]</item>
                     <label>analytical domain</label>
                     <item>The analytical domain is comprised of any number of theoretical analyses
                        and/or commentaries, each of which somehow specifies opinions, exegeses,
                        etc. about any or all of the information in the other three domains.
                        […]</item>
                  </list>
                  <p>On a generic level, MEI follows the same definition, and it definitely shares
                     the same terminology. However, not all four domains are available throughout
                     the MEI schema, and quite frequently, two domains fall together in MEI. Very
                     often, <hi rend="italic">MEI prioritizes the visual domain over the gestural domain</hi> by (partly)
                     <hi rend="italic">conflating the logical and the visual domains</hi>. For example, MEI utilizes the
                     <att>pname</att> (pitch name) attribute on notes to capture the <hi rend="italic">written</hi>
                     pitch of a note, whereas the sounding pitch may be described with the
                        <att>pname.ges</att> attribute. Here, the logical and visual domains go
                     without a special indication, whereas the gestural domain is identified by a
                     special suffix. However, in case of transposing instruments, additional markup
                     (namely the attributes <att>trans.diat</att> and <att>trans.semi</att> from
                     MEI’s attribute class <ident type="class">att.staffDef.log</ident>) will create
                     a distinction between the logical and visual domain (see chapter <ptr
                        target="#cmnDefs"/>). In that case, <att>pname</att> will be restricted to
                     the visual domain, while the logical aforementioned attributes provide
                     additional information for the logical domain.</p>
                  <p>Even though the technical implementation of MEI prioritizes the visual domain
                     to some degree, this does not mean that any given encoding has to provide
                     visual information. MEI takes no assumption on what data is required: While an
                     OMR project (<hi rend="italic">optical music recognition</hi>) may generate strictly visually
                     oriented data only, another project focussed on audio transcriptions may
                     generate gestural data only. A third project could integrate both
                     approaches.</p>
                  <p>In order to avoid ambiguous encodings, MEI is very strict and specific on the
                     scope of its individual markup elements. For an encoder, the suffixes mentioned
                     above provide clear hints on which domain is addressed by specific markup: Many
                     attributes carry a suffixed <hi rend="italic">.log</hi> (logical), <hi rend="italic">.ges</hi> (gestural), <hi rend="italic">.vis</hi>
                     (visual), or <hi rend="italic">.anl</hi> (analytical) in their name. In addition, the internal
                     structure of MEI heavily relies on those different domains. When customizing
                     MEI (see chapter <ptr target="#meiCustomization"/>), it is possible to turn off
                     either visual or gestural domain encoding completely. That way, MEI allows to
                     address the four most eminent musical domains specifically and independent of
                     each other.</p>
               </div>
               <div xml:id="eventsControlevents" type="div3">
                  <head>Events and Controlevents</head>
                  <p>MEI differentiates between two essential aspects of music notation: <hi
                        rend="italic">Events</hi> and <hi rend="italic">ControlEvents</hi>. There
                     are other examples for such a separation of concerns with regard to music. In
                     Greg’s Copy-Text Theory (W.W. Greg: <hi rend="italic">The Rationale of
                        Copy-Text</hi>, 1950), a distinction between primary and secondary text is
                     made; similar attempts have been made for music specifically.</p>
                  <p>In MEI, elements describing the basic musical text are referred to as <hi
                        rend="italic">Events</hi>. They are the building blocks for the stream of
                     music – mostly those are <gi scheme="MEI">note</gi>s, <gi scheme="MEI"
                        >rest</gi>s, and <gi scheme="MEI">chord</gi>s. In contrast, <hi
                        rend="italic">ControlEvents</hi> make no independent contribution to that
                     flow of music. Instead, they provide additional information about the encoded
                        <hi rend="italic">Events</hi>, they <hi rend="italic">control</hi> their
                     performance. Examples for such <hi rend="italic">ControlEvents</hi> are <gi
                        scheme="MEI">dynam</gi>ic markings, <gi scheme="MEI">tempo</gi>s
                     indications, or performance <gi scheme="MEI">dir</gi>ectives. Depending on the
                     encoding strategy used, <gi scheme="MEI">slur</gi>s and <gi scheme="MEI"
                        >tie</gi>s often also fall into this category (they may be encoded as
                     attributes instead, in which case they become a property of the basic events).
                     Simply put, <hi rend="italic">Events</hi> describe <hi rend="bold italic"
                        >what</hi> needs to be performed, and <hi rend="italic">ControlEvents</hi>
                     indicate <hi rend="bold italic">how</hi> it needs to be performed. In (<ptr
                        target="#cmn"/>-based) MEI, <hi rend="italic">Events</hi> are nested inside
                     a <gi scheme="MEI">layer</gi> element, while <hi rend="italic"
                        >ControlEvents</hi> are direct children of the first <gi scheme="MEI"
                        >measure</gi> they apply to, following all <gi scheme="MEI">staff</gi>
                     elements there. These structural differences result in different markup
                     concepts. As <hi rend="italic">Events</hi> are encoded inside <gi scheme="MEI"
                        >layer</gi>s, their <hi rend="italic">semantic position</hi> inside the
                     encoded work can be derived from their <hi rend="italic">structural
                        position</hi> – the measure, staff and layer they're nested in, and within
                     that layer by their position inside the sequence of all layer children. As
                     mentioned above, it is highly <hi rend="italic">recommended</hi> to encode <hi
                        rend="italic">ControlEvents</hi> inside the first measure they apply to, but
                     they still require references to the actual events they apply to. There are two
                     common concepts to provide such a connection, both of which offering specific
                     benefits and drawbacks. A technically very stable connection between <hi
                        rend="italic">ControlEvents</hi> and <hi rend="italic">Events</hi> can be
                     established by using <hi rend="italic">pointers</hi>. In this case, all events
                     that need to be referenced need an <att>xml:id</att> attribute, which holds a
                     globally unique identifier for this very element. The referencing controlevent
                     then uses a <att>startid</att> and, if necessary, <att>endid</att> attribute to
                     create a link to where in the stream of music it is supposed to start or
                     end.</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/shared/controlevents-dynam1.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>In the example above, the <gi scheme="MEI">dynam</gi> element references the
                     second quarter in the given measure. Additional attributes like
                        <att>place</att> may be used to describe the position of the <hi
                        rend="italic">forte</hi> indication within the score. A <gi scheme="MEI"
                        >hairpin</gi> element may use the <att>endid</att> attribute to indicate the
                     duration of the hairpin using the same mechanism as above.</p>
                  <p>
                     <specList>
                        <specDesc key="att.startId" atts="startid"/>
                        <specDesc key="att.startEndId" atts="endid"/>
                     </specList>
                  </p>
                  <p>A <hi rend="italic">ControlEvent</hi> encoded like above will be strictly tied
                     to the referenced <hi rend="italic">Events</hi> – if their position inside the
                     XML document changes for whatever reason, they will keep that connection. This
                     means that the <hi rend="italic">semantic position</hi> to which they are bound
                     may change without affecting the binding. An example could be an inserted
                     additional note in front – the dynamic marking would not start on the second
                     quarter, but perhaps on the third instead.</p>
                  <p>As this behavior may not be desired in all cases, an alternative binding
                     between <hi rend="italic">ControlEvents</hi> and <hi rend="italic">Events</hi>
                     is possible, relying on <hi rend="italic">timestamps</hi> instead. This
                     mechanism is illustrated in the following example:</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/shared/controlevents-dynam2.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>Here, no <att>xml:id</att> is required on notes. Instead, the <gi scheme="MEI"
                        >dynam</gi> element uses the <att>staff</att> and <att>layer</att>
                     attributes to indicate to which set of events the following <att>tstamp</att>
                     attribute refers to.</p>
                  <p>
                     <specList>
                        <specDesc key="att.timestamp.log" atts="tstamp"/>
                     </specList>
                  </p>
                  <p>This mechanism actually depends on what has been only recommended above:
                     placing the controlevent inside the measure where it starts. The
                        <att>startid</att> reference mechanism would work equally well if all
                     controlevents where positioned in the very first or last measure, or actually
                     even inside a separate file. The <att>tstamp</att> references however would
                     not, they depend on correct placement of the controlevents inside the XML tree.
                     For consistency, it is therefore <hi rend="italic">recommended</hi> to always
                     use this placement.</p>
                  <p>The benefit of this concept is that controlevents are tied to a <hi
                        rend="italic">semantic position</hi>, but not necessarily to a given XML
                     element. The <hi rend="italic">forte</hi> may still be placed on the second
                     quarter, even though the composer may have replaced that quarter G4 with a
                     different pitch and / or duration. Actually, it is not required that an <hi
                        rend="italic">Event</hi> can be found at the position indicated by a
                     timestamp. This may be useful to encode a slur ending at an arbitrary position
                     between two events, or dynam markings spread across otherwise empty
                     measures.</p>
                  <p>If the ending of a <hi rend="italic">ControlEvent</hi> shall be given by
                     timestamp, the <att>tstamp2</att> attribute is used.</p>
                  <p>
                     <specList>
                        <specDesc key="att.timestamp2.log" atts="tstamp2"/>
                     </specList>
                  </p>
                  <p>Because of potential inconsistencies, an encoding should not offer both
                        <att>startid</att> and <att>tstamp</att> or <att>endid</att> and
                        <att>tstamp2</att>. Though not being recommendable, it is possible to mix
                        <att>startid</att> with <att>tstamp2</att> and <att>tstamp</att> with
                        <att>endid</att>. In general, it is easier for software to process
                        <att>startid</att> and <att>endid</att>. When no other arguments apply,
                     using <att>xml:id</att>-based pointers is therefore the most common way to
                     connect <hi rend="italic">ControlEvents</hi> with <hi rend="italic"
                     >Events</hi>.</p>
                  <p>The details on how timestamps are calculated and used in MEI are given in <ptr
                        target="#timestamps"/>.</p>
               </div>
               <div xml:id="timestamps" type="div3">
                  <head>Timestamps in MEI</head>
                  <p>In MEI, timestamps are treated in a slightly simplified way: they have no
                     notion of <hi rend="italic">beat</hi>. Instead, timestamps rely solely on the
                     numbers given in the meter signature. In a measure of 4/4, timestamps will
                     range from 1 to 4. The second eighth note will be 1.5 in this case. If the same
                     measure would be given in 2/2, it would be 1.25 instead.</p>
                  <p>
                     <specList>
                        <specDesc key="att.timestamp.log" atts="tstamp"/>
                     </specList>
                  </p>
                  <p>At this point, MEI uses real numbers only to express timestamps. In case of
                     (nested or complex) tuplets, this solution is inferior to fractions because of
                     rounding errors. It is envisioned to introduce a fraction-based value for
                     timestamps in a future revision of MEI. For now, it is recommended to round the
                     fractional part of the number to no more than five digits to avoid such
                     problems.</p>
                  <p>Durations may also be expressed based on timestamps. In this case, the values
                     are a combination of the <hi rend="italic">count of measures</hi> that need to
                     be moved forward to reach the measure in which an encoded feature ends, and the
                        <hi rend="italic">timestamp</hi> within that measure.</p>
                  <p>
                     <specList>
                        <specDesc key="att.timestamp2.log" atts="tstamp2"/>
                     </specList>
                  </p>
                  <p>The following example contains a number of <gi scheme="MEI">slur</gi> examples
                     illustrating durations expressed by timestamps.</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/shared/timestamp-durations1.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>Sometimes, timestamps are used to indicate positions where no music <hi
                        rend="italic">Events</hi> are located (see <ptr
                        target="#eventsControlevents"/>). Therefore, the allowed range of timestamps
                     stretches from 0 to the current meter count + 1. By definition, a timestamp of
                     1 indicates the position of the left bar line, while a timestamp of 5 (in case
                     of a 4/4 meter) indicates the right bar line. This makes it possible to encode
                     open-ended slurs in a graphical way. However, it should be kept in mind that
                     such timestamps may not be converted to <att>startid</att> and
                     <att>endid</att>, and not every application may be able to render them
                     correctly, even though they are perfectly valid MEI, and sometimes are
                     necessary to faithfully transcribe a source.</p>
               </div>
               <div xml:id="meiProfiles" type="div3">
                  <head>MEI Profiles</head>
                  <p>MEI is an encoding framework, not a data format. This means that MEI provides
                     recommendations for encoding music documents, but it depends on the encoder's
                     needs and requirements to which features and solutions are appropriate to the
                     task and should be used. MEI offers specific models for different notation
                     types and music repertoires, but it is rarely advisable to use them all side by
                     side in one encoding.</p>
                  <p>In order to use MEI, it is advised to use a restricted version of the schema,
                     which will make it easier both for an encoder and a reader of the encoded
                     files. MEI provides a number of pre-defined <hi rend="italic">profiles</hi>, which focus on specific
                     uses of MEI while still maintaining a great level of flexibility. For projects
                     that need even better control over their data, it is highly recommended to
                     create a more specific customized version of MEI (see chapter <ptr
                        target="#meiCustomization"/>). The following customizations are provided
                     with every release of MEI:</p>
                  <list type="gloss">
                     <label>mei-CMN</label>
                     <item>For most users, this will be the best starting point into music
                        encoding with MEI. The <hi rend="italic">mei-CMN</hi> customization targets at documents that use
                        <hi rend="italic">Common Western Music Notation</hi>. The specific rules for that notation are
                        specified in chapter <ptr target="#cmn"/>, even though other chapters of these
                        Guidelines apply as well.</item>
                     <label>mei-Mensural</label>
                     <item>For documents written in <hi rend="italic">Mensural Notation</hi> (both black and
                        white), MEI offers the <hi rend="italic">mei-Mensural</hi> customization. The specific rules for
                        that notation are specified in chapter <ptr target="#mensural"/>, even though
                        other chapters of these Guidelines apply as well.</item>
                     <label>mei-Neumes</label>
                     <item>This profile allows to encode medieval <hi rend="italic">Neume Notation</hi> with MEI.
                        The specific rules for that notation are specified in chapter <ptr
                           target="#neumes"/>, even though other chapters of these Guidelines apply as
                        well. Please note that the <hi rend="italic">mei-Neumes</hi> profile has undergone significant
                        changes from MEI version 3 to version 4.</item>
                     <label>mei-Basic</label>
                     <item>As an encoding framework, MEI offers multiple approaches to encode
                        certain features at various levels of detail. While this flexibility is at the
                        core of MEI and often required for research projects, it is an obstacle when
                        developing software and converters for MEI. The <hi rend="italic">mei-Basic</hi> profile is a subset
                        of MEI which restricts it to one way of encoding for every feature of music
                        notation. It covers <hi rend="italic">Common Western Music Notation</hi> only, and excludes all
                        editorial markup. In essence, it has the same functionality as most other music
                        encoding formats like MusicXML or MNX. The purpose of <hi rend="italic">mei-Basic</hi> is to serve
                        as common ground for data interchange, both between projects using different
                        profiles of MEI, and other encoding schemes.</item>
                     <label>mei-all</label>
                     <item>This is the full definition of MEI. It includes all different
                        repertoires, which has certain side effects and enables encoding options that
                        are neither intended nor advocable. For example, in mensural notation music is
                        organized by staves. In contrast, Common Music Notation utilizes measures,
                        which in turn contain staves. These staves have a different meaning here, and
                        are modeled differently in MEI. <hi rend="italic">mei-all</hi> mixes those models and thus invites
                        encoding errors. In general, you should almost never use <hi rend="italic">mei-all</hi> except for
                        testing purposes.</item>
                     <label>mei-all_anyStart </label>
                     <item>This profile includes all of <hi rend="italic">mei-all</hi>, but extends it even
                        further so that it allows any MEI element as root of conforming MEI instances.
                        In regular MEI, the only allowed starting elements are <gi scheme="MEI"
                           >mei</gi>, <gi scheme="MEI">meiHead</gi>, <gi scheme="MEI">music</gi> and
                        <gi scheme="MEI">meiCorpus</gi>. The sole purpose of this customization is
                        to simplify validation at tutorial sessions and other educational purposes. It
                        should not be used in production.</item>
                  </list>
                  <p>The first three profiles provide good starting points to encode music from the
                     respective repertoires. They may also serve as template for further,
                     project-specific customizations. The latter two profiles target very
                     specific use cases and should not be used by default.</p>
               </div>
               <div xml:id="meiCustomization" type="div3">
                  <head>Customizing MEI</head>
                  <p>In production, it is best to use a customized version of MEI, restricted to the
                     very needs of a project. Such a custom schema will guide the encoders and will
                     help to ensure consistency and data quality throughout a project’s files. A
                     customization typically provides a subset of MEI’s encoding models (typically
                     starting from one of the official <hi rend="italic">profiles</hi> mentioned in chapter <ptr
                        target="#meiProfiles"/>), with only one solution for any given situation
                     being allowed. The customization will help to reflect the scope of a project
                     into its data: Only those aspects of music notation a project is interested in
                     will be allowed, so that the absence of a specific information can not be
                     misunderstood as an oversight of the encoders. Larger editorial projects like
                     <hi rend="italic">Complete Works</hi> editions typically use <hi rend="italic">Editorial Guidelines</hi> (german:
                     <hi rend="italic">Editionsrichtlinien</hi>) for the same purposes: (internal) quality control and
                     (external) documentation. In that sense, MEI customizations may serve as
                     Editorial Guidelines in digital form.</p>
                  <p>MEI is implemented in ODD. ODD, or <hi rend="italic">One Document Does-it-all</hi>, is another
                     XML-based markup language developed and maintained by the TEI. TEI's
                     documentation for ODD can be found in the TEI Guidelines chapter 22: <ref
                        target="http://www.tei-c.org/release/doc/tei-p5-doc/en/html/TD.html"
                        >Documentation Elements</ref>, chapter 23: <ref
                        target="http://www.tei-c.org/release/doc/tei-p5-doc/en/html/USE.html">Using
                        the TEI</ref>, and the "<ref
                        target="https://tei-c.org/guidelines/customization/getting-started-with-p5-odds/"
                        >Getting Started with P5 ODDs</ref>" document.</p>
                  <p>At this point, there is no specific documentation on how to customize MEI with
                     ODD beyond the generic TEI documentation. However, the provided <ptr
                        target="#meiProfiles"/> are based on ODD customizations, and may serve as
                     starting point for further project-specific restrictions. They can be found
                        at <ref
                        target="https://github.com/music-encoding/music-encoding/tree/dev/customizations"
                        >https://github.com/music-encoding/music-encoding/tree/dev/customizations</ref>.
                     In addition, several projects have shared their customizations on GitHub, such
                        as <ref
                        target="https://github.com/Freischuetz-Digital/data-music/tree/master/schemata/odd"
                        >Freischütz Digital</ref> or <ref
                        target="https://github.com/BeethovensWerkstatt/module2/tree/dev/data/odd"
                        >Beethovens Werkstatt</ref>.</p>
                  <p>MEI provides a web service at <ref target="http://custom.music-encoding.org/"
                        >http://custom.music-encoding.org</ref> which allows to
                     compile such customizations against the MEI sources in order to generate
                     RelaxNG schemata, which can be used for validation. More documentation on
                     customizing MEI will be provided as time permits; until then, it is recommended
                        to <ref target="https://music-encoding.org/community/community-contacts.html"
                        >reach out to the MEI Community</ref> for additional
                     assistance.</p>
               </div>
            </div>
            <div xml:id="samplesTools" type="div2">
               <head>Sample Encodings and Tools for MEI</head>
               <p>The Music Encoding Initiative provides a collection of sample encodings, which
                  demonstrate a wide-range of uses of MEI in real-world contexts. They are available
                     from <ref target="https://github.com/music-encoding/sample-encodings"
                     >https://github.com/music-encoding/sample-encodings</ref>.</p>
               <p>For MEI, there is also a number of tools, which facilitate encoding of and working
                  with MEI instances in various contexts. These tools are available from the <ref
                     target="https://music-encoding.org/resources/tools.html"
                     >https://music-encoding.org/resources/tools.html</ref> website.</p>
            </div>
         </div>
      </body>
   </text>
</TEI>
