<?xml version="1.0" encoding="UTF-8"?>
<!-- 
  NOTICE: Copyright (c) by the Music Encoding Initiative (MEI) Board (formerly known as "MEI Council").

  Licensed under the Educational Community License, Version 2.0 (the "License"); you may
  not use this file except in compliance with the License. You may obtain a copy of the License
  at https://opensource.org/licenses/ECL-2.0.
  
  Unless required by applicable law or agreed to in writing, software distributed under the
  License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS
  OF ANY KIND, either express or implied. See the License for the specific language
  governing permissions and limitations under the License.
  
  This is a derivative work based on earlier versions of the schema © 2001-2006 Perry Roland
  and the Rector and Visitors of the University of Virginia; licensed under the Educational
  Community License version 1.0.
  
  CONTACT: info@music-encoding.org
-->
<?xml-model href="../validation/mei_odds.rng" type="application/xml" schematypens="http://purl.oclc.org/dsdl/schematron"?>
<?xml-model href="../validation/mei_odds.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?>
<TEI xmlns:rng="http://relaxng.org/ns/structure/1.0"
     xmlns:sch="http://purl.oclc.org/dsdl/schematron"
     xmlns="http://www.tei-c.org/ns/1.0"
     version="5.0"
     rend="book"
     xml:lang="en">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <title level="s">The Music Encoding Initiative Guidelines</title>
            <title level="a">Facsimiles and Recordings</title>
            <respStmt>
               <resp>Edited by</resp>
               <name role="edt">Johannes Kepper</name>
               <note>The editors listed here are responsible for the contents of this very chapter of the MEI Guidelines.</note>
            </respStmt>
            <respStmt>
               <resp>With contributions by</resp>
               <!--TODO: To be filled automatically via GitHub API-->
               <name ref="https://api.github.com/users/bwbohl">Benjamin W. Bohl</name>
               <name ref="https://api.github.com/users/BruxDDay">BruxDDay</name>
               <name ref="https://api.github.com/users/ndubo">Norbert Dubowy</name>
               <name ref="https://api.github.com/users/fujinaga">Ichiro Fujinaga</name>
               <name ref="https://api.github.com/users/axgeertinger">Axel Geertinger</name>
               <name ref="https://api.github.com/users/ahankinson">Andrew Hankinson</name>
               <name ref="https://api.github.com/users/irmlindcapelle">irmlindcapelle</name>
               <name ref="https://api.github.com/users/frakel">franz kelnreiter</name>
               <name ref="https://api.github.com/users/kepper">kepper</name>
               <name ref="https://api.github.com/users/zolaemil">Zoltan Komives</name>
               <name ref="https://api.github.com/users/DDMAL-LabManager">DDMAL LabManager</name>
               <name ref="https://api.github.com/users/uliska">Urs Liska</name>
               <name ref="https://api.github.com/users/elsinhadl">Elsa De Luca</name>
               <name ref="https://api.github.com/users/napulen">Néstor Nápoles López</name>
               <name ref="https://api.github.com/users/MajaHartwig">MajaHartwig</name>
               <name ref="https://api.github.com/users/musicEnfanthen">Stefan Münnich</name>
               <name ref="https://api.github.com/users/pe-ro">pe-ro</name>
               <name ref="https://api.github.com/users/lpugin">Laurent Pugin</name>
               <name ref="https://api.github.com/users/JRegimbal">Juliette Regimbal</name>
               <name ref="https://api.github.com/users/rettinghaus">Klaus Rettinghaus</name>
               <name ref="https://api.github.com/users/aseipelt">Agnes Seipelt</name>
               <name ref="https://api.github.com/users/martha-thomae">Martha E. Thomae</name>
               <name ref="https://api.github.com/users/raffazizzi">Raffaele Viglianti</name>
               <name ref="https://api.github.com/users/vigliensoni">Gabriel Vigliensoni</name>
               <name ref="https://api.github.com/users/th-we">Thomas Weber</name>
               <name ref="https://api.github.com/users/musicog">David M. Weigl</name>
            </respStmt>
         </titleStmt>
         <publicationStmt>
            <distributor>Music Encoding Initiative (MEI) Board</distributor>
            <availability>
               <p>
                  <hi>Music Encoding Initiative (MEI)</hi>
               </p>
               <p>NOTICE: Copyright (c) by the Music Encoding Initiative (MEI) Board (formerly known as "MEI Council").</p>
               <p>Licensed under the Educational Community License, Version 2.0 (the "License"); you may
                                            not use this file except in compliance with the License. You may obtain a copy of the
                                            License at <ref target="http://opensource.org/licenses/ECL-2.0">http://opensource.org/licenses/ECL-2.0</ref>.</p>
               <p>Unless required by applicable law or agreed to in writing, software distributed under
                                            the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
                                            KIND, either express or implied. See the License for the specific language governing
                                            permissions and limitations under the License.</p>
               <p>This is a derivative work based on earlier versions of the schema copyright (c)
                                            2001-2006 Perry Roland and the Rector and Visitors of the University of Virginia;
                                            licensed under the Educational Community License version 1.0.</p>
               <p>CONTACT: contact@music-encoding.org </p>
            </availability>
         </publicationStmt>
         <sourceDesc>
            <p>Born digital: No previous source exists.</p>
         </sourceDesc>
      </fileDesc>
   </teiHeader>
   <text>
      <body>
         <div xml:id="facsimilesrecordings" type="div1">
            <head>Facsimiles and Recordings</head>
            <p>MEI can be used to connect an encoding of some sort – either a transcription of existing material, or the specification of some expected output in some form – with existing sources. This existing material may be in different formats – music notation in any combination of print and manuscript, or audio or video footage. The concepts for establishing such connections between encoded music and source material is described in the following chapters.</p>
            <div xml:id="facsimiles" type="div2">
               <head>Facsimiles</head>
               <p>Most often, MEI is used for the preparation of a digital musical text based on an existing music document, or with the intention of rendering the encoded notation into a document or audio rendition. MEI can, however, be used to provide a different kind of digital reproduction of a source document, which relies on the description and provision of digital imagery. Both approaches may be combined, so that the encoding of the musical content and digital facsimiles may add different facets to the same MEI document.</p>
               <div xml:id="facsimileElements" type="div3">
                  <head>Elements of the Facsimile Module</head>
                  <p>This module makes available the following elements for encoding facsimiles:</p>
                  <p>
                     <specList>
                        <specDesc key="facsimile"/>
                        <specDesc key="surface"/>
                        <specDesc key="zone"/>
                     </specList>
                  </p>
                  <p>These element are used to add a separate subtree to MEI, starting with the <gi scheme="MEI">facsimile</gi> element inside <gi scheme="MEI">music</gi>, as seen in the following example:</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/facsimiles/facsimiles-sample244.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>It is possible to have more than one <gi scheme="MEI">facsimile</gi> element in this location. This is especially useful when multiple sources are encoded in the same file using the mechanisms described in chapter <ptr target="#editTrans"/> of these Guidelines. In this case, the <att>decls</att> (declarations) attribute of <gi scheme="MEI">facsimile</gi> may be used to refer to a source defined in the document’s header, as seen in the following example:</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve" valid="feasible"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/facsimiles/facsimiles-sample245.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>When using the FRBR model (see <ptr target="#FRBR"/>), it is equally possible to reference a <gi scheme="MEI">manifestation</gi> element instead of <gi scheme="MEI">source</gi>.</p>
                  <p>Within a <gi scheme="MEI">facsimile</gi> element, each page of the source is represented by a <gi scheme="MEI">surface</gi> element. Each surface may be assigned an identifying string utilizing the <att>label</att> attribute. In addition, it may encapsulate more detailed metadata about itself in a <gi scheme="MEI">figDesc</gi> element. The coordinate space of the surface may be recorded in abstract terms in the <att>ulx</att>, <att>uly</att>, <att>lrx</att>, and <att>lry</att> attributes. For navigation purposes, <gi scheme="MEI">surface</gi> has a <att>startid</att> attribute that accommodates pointing to the first object appearing on this particular writing surface.</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/facsimiles/facsimiles-sample246.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>Within <gi scheme="MEI">surface</gi> elements, one may nest one or more <gi scheme="MEI">graphic</gi> elements, each providing a reference to an image file that represents the writing surface. Multiple <gi scheme="MEI">graphic</gi> elements are permitted in order to accommodate alternative versions (different resolutions or formats, for instance) of the surface image. In spite of changes in resolution or format, all images must contain the same content, <abbr>i.e.</abbr>, the entire writing surface. A <gi scheme="MEI">graphic</gi> may refer to a single page within a multi-page document, which is – at least for Adobe PDF documents – available through a #page=X suffix to the <att>target</att> attribute.</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/facsimiles/facsimiles-sample247.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>The preceding markup will provide the basis for most page-turning applications. Often, however, it is desirable to focus attention on particular areas of the graphical representation of the surface. The <gi scheme="MEI">zone</gi> element fulfills this purpose:</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/facsimiles/facsimiles-sample248.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>The coordinates of each zone <hi rend="italic">define a space relative to the coordinate space of its parent surface</hi>. Note that this is not necessarily the same coordinate space defined by the width and height attributes of the graphic that represents the surface. The zone coordinates in the preceding example do not represent regions within the graphic, but rather regions of the <hi rend="italic">writing surface</hi>.</p>
                  <p>Because the coordinate space of a zone is defined relative to that of a surface, it is possible to provide multiple graphic elements <hi rend="italic">and</hi> multiple zone elements within a single surface. In the following example, two different images representing the entire surface are provided alongside specification of two zones of interest within the surface:</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/facsimiles/facsimiles-sample249.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>A <gi scheme="MEI">zone</gi> element may contain <gi scheme="MEI">figDesc</gi> or <gi scheme="MEI">graphic</gi> elements that provide detailed descriptive information about the zone and additional images, e.g., at a different/higher resolution, of the rectangle defined by the zone. The data objects contained within the zone may also be specified through the use of the <att>data</att> attribute, which contains ID references to one more elements in the content tree of the MEI file, such as a <gi scheme="MEI">note</gi>, <gi scheme="MEI">measure</gi>, etc.</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve" valid="feasible"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/facsimiles/facsimiles-sample250.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>Conversely, an element in the content may refer to the <gi scheme="MEI">facsimile</gi> subtree using its <att>facs</att> attribute, which is made available by the <ident type="class">att.facsimile</ident> attribute class. The last example could therefore be encoded with pointers in the other direction:</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve" valid="feasible"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/facsimiles/facsimiles-sample251.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>The <gi scheme="MEI">pb</gi> element defined in the <ptr target="#shared"/> makes special use of the <att>facs</att> attribute, in that it does not point to a <gi scheme="MEI">zone</gi>, but a <gi scheme="MEI">surface</gi> element instead. A <gi scheme="MEI">pb</gi> marks the beginning of a page, so it can be concluded that all elements in the content tree which are encoded between any two <gi scheme="MEI">pb</gi> elements encode musical symbols written on the page (<gi scheme="MEI">surface</gi>) referenced by the first of these two <gi scheme="MEI">pb</gi> element’s <att>facs</att> attribute.</p>
                  <p>The encoding of <gi scheme="MEI">facsimile</gi> elements is intended to support sequential display of page images. If an encoder wants to describe the physical setup of a source document, the <gi scheme="MEI">foliaDesc</gi> element is more appropriate. The difference of both approaches, and how to combine them, is described in chapter <ptr target="#foliadesc"/>.</p>
               </div>
            </div>
            <div xml:id="performances" type="div2">
               <head>Performances</head>
               <p>This chapter describes the ‘performance’ module, which can be used for organizing audio and video files of performances of a musical work. The elements provided allow the encoder to group different recordings of the same performance, identify temporal segments within the recordings, and encode simple alignments with a music text.</p>
               <div xml:id="perfElements" type="div3">
                  <head>Overview</head>
                  <p>The following elements are available to encode information about a recorded performance:</p>
                  <p>
                     <specList>
                        <specDesc key="performance"/>
                        <specDesc key="recording"/>
                        <specDesc key="avFile"/>
                        <specDesc key="clip"/>
                        <specDesc key="when"/>
                     </specList>
                  </p>
                  <p>The <gi scheme="MEI">performance</gi> element begins a subtree of the <gi scheme="MEI">music</gi> element and appears alongside with, or instead of, <gi scheme="MEI">body</gi> (described in <ptr target="#sharedMusicElement"/>) and <gi scheme="MEI">facsimile</gi> (described in <ptr target="#facsimiles"/>). A <gi scheme="MEI">performance</gi> element represents one recorded performance event. As a performance may be recorded in multiple formats or by different personnel or using different equipment, the <gi scheme="MEI">performance</gi> element may group one or more recordings of the event.</p>
                  <p>The <att>decls</att> attribute can be used to point to performance medium metadata for the performed work. See <ptr target="#headerWorkMedium"/> and <ptr target="#FRBR"/> for more details.</p>
                  <p>The <gi scheme="MEI">recording</gi> element identifies a single recording event taking place within an absolute temporal space. The class <ident type="class">att.mediaBounds</ident> contains attributes that can be used to define this space:</p>
                  <p>
                     <specList>
                        <specDesc key="att.mediaBounds" atts="begin end betype"/>
                     </specList>
                  </p>
                  <p>The <gi scheme="MEI">avFile</gi> element identifies an external file associated with a recording act. In the simplest case, the recording element will contain one <gi scheme="MEI">avFile</gi> element identifying a file that represents it. The <att>target</att> attribute contains the URI of the digital media file. Use of the <att>mimetype</att> attribute is recommended for the <gi scheme="MEI">avFile</gi> element. Its value should be a valid MIME media type defined by the Internet Engineering Task Force in RFC 2046. It is also recommended that all avFile elements have a recording or clip parent which bears the <att>begin</att>, <att>end</att>, and <att>betype</att> attributes.</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/performances/performances-sample321.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>Sometimes, multiple digital files are created in order to provide greater flexibility in redistribution and playback capabilities. In this case, multiple avFile elements may occur, each with a different mimetype. Keep in mind, however, that each file still represents the complete temporal extent of the recording act in spite of the change of file format:</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/performances/performances-sample322.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>The <gi scheme="MEI">clip</gi> element identifies a temporal segment of a recording act. In the following example, the clip begins two minutes into the timeframe of the recording and ends 20 seconds later:</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/performances/performances-sample323.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>Beyond these relatively simple uses, complex situations may occur that require equally complex markup. For example, a single performance may be represented by multiple digital media files. Because they have differing durations, the media files must be the result of separate recording acts, even if these recording acts took place at the same time:</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/performances/performances-sample324.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>A single performance may also be represented by multiple, <hi rend="italic">sequential</hi> digital files, as when a complete work is recorded in several so-called ‘takes’. In this case, the files may be considered to be parts of a single recording act, the extent of which is the combined extent of the individual clips. For example, a series of <gi scheme="MEI">clip</gi> elements may be used to identify each movement of a piece and give start and end times for the movements in relation to the overall temporal space of the complete work:</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/performances/performances-sample325.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>Similar markup is also applicable when a single file representing the entirety of a recording act is broken into segments later, as is often done for practical storage and distribution reasons. The file from which the clips are derived is indicated using an avFile element:</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/performances/performances-sample326.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>A <gi scheme="MEI">clip</gi> may be used to define any region of interest, such as a cadenza or a modulation, a song verse, etc. The following example shows the use of <gi scheme="MEI">clip</gi> and its attributes to identify significant sections of a recording:</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/performances/performances-sample327.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>The preceding example also demonstrates that media files are not required in order to define the temporal space of a recording act or clip. This makes it possible to set the boundaries of these features, then use the content of the performance element as a rudimentary "edit decision list" to create the matching digital files.</p>
                  <p>If an encoding of the notated text with which the media files are associated is included in the MEI file, the <att>startid</att> attribute can be used to indicate the first element in the sequence of events to which the recording corresponds:</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve" valid="feasible"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/performances/performances-sample328.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>Clips can also be aligned with components of the musical text encoded in the <gi scheme="MEI">body</gi>. The <att>startid</att> attribute can be used to specify the starting element in the sequence of events to which the clip corresponds. The following example shows the use of clip elements to identify the exposition of the first movement from Beethoven’s piano sonata Op. 14, no. 2 and its concluding ‘codetta’.</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve" valid="feasible"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/performances/performances-sample329.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>Please note that the begin and end times of clips may overlap. In the preceding example, the extent of the codetta is contained within that of the exposition. Overlapping beginning and ending points may also be used to provide additional performance context for a segment or because there is uncertainty with regard to precise values for these points.</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/performances/performances-sample330.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>A bibliographic description of a recording or metadata explaining how clip boundaries were determined may be associated with the recording and clip elements via the <att>decls</att> attribute:</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/performances/performances-sample331.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>Associations between a feature of the encoding, such as a note, dynamic mark, or annotation, and a time point, may be created using <gi scheme="MEI">when</gi> elements and <att>when</att> attributes.</p>
                  <p>The <gi scheme="MEI">when</gi> element identifies a particular point in time during the playback of a media file, such as an audio recording.</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/performances/performances-sample332.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>Time points may be identified in absolute terms as above; that is, in hours, minutes, and seconds since the beginning of the recording, or in relative terms using the <att>interval</att>, <att>inttype</att>, and <att>since</att> attributes. In the following example, the time point of interest happens 48 frames after the occurrence of the point labelled as "t1".</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/performances/performances-sample333.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>Having identified a point of interest, another feature of the encoding may be associated with this point using its <att>when</att> attribute:</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/performances/performances-sample334.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>One use of the association created between the annotation and the time point is to display the text of the annotation as the recording or clip is played.</p>
                  <p>The <att>when</att> attributes allows only a single value, so only one-to-one relationships can be created using this mechanism. However, one-to-many relationships are accommodated in the opposite direction; that is, from a time point to other features of the markup. For example,</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/performances/performances-sample335.txt" parse="text"/></egXML>
                     </figure>
                  </p>
                  <p>indicates that the entities identified in <att>data</att> all occur at the same instant.</p>
                  <p><gi scheme="MEI">extData</gi> is a container for holding non-MEI data formats, similar to <gi scheme="MEI">extMeta</gi> but available in <gi scheme="MEI">when</gi> rather than in <gi scheme="MEI">meiHead</gi>. <gi scheme="MEI">extData</gi> allows for data from audio or other sources to be linked to notes or other score events. Data should be enclosed in a CDATA tag.</p>
                  <p>The following example shows JSON formatted performance data encoded with <gi scheme="MEI">extMeta</gi> for a single note (presumed to be defined elsewhere in the document as with the ID "note_1"). Both single-value summaries (<abbr>e.g.</abbr>, pitch) and time series values (<abbr>e.g.</abbr>, contF0) are encoded.</p>
                  <p>
                     <figure>
                        <head/>
                        <egXML xmlns="http://www.tei-c.org/ns/Examples" rend="code" xml:space="preserve"><xi:include xmlns:xi="http://www.w3.org/2001/XInclude" href="../examples/performances/performances-sample336.txt" parse="text"/></egXML>
                     </figure>
                  </p>  
               </div>
            </div>
         </div>
      </body>
   </text>
</TEI>
