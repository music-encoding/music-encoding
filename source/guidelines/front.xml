<?xml version="1.0" encoding="UTF-8"?>
<front xmlns="http://www.tei-c.org/ns/1.0">
  <titlePage>
    <docTitle>
      <titlePart>
        <hi rend="bold">Music Encoding Initiative Guidelines</hi>
      </titlePart>
    </docTitle>
    <docEdition>
      <hi rend="bold">Version 3.0.0</hi>
    </docEdition>
    <byline><lb/><lb/>Prepared and maintained by the Music Encoding Initiative Council<lb/><lb/><lb/><lb/>
      <figure rend="center">
        <graphic url="Images/meilogo.png"/>
      </figure>
      <lb/><lb/><lb/><lb/>
    </byline>
    <byline>Edited by Perry Roland and Johannes Kepper<lb/><lb/>With contributions by Benjamin Bohl,
      Andrew Hankinson, Maja Hartwig, Zoltán Kömíves,<lb/>Laurent Pugin, Kristina Richts, Raffaele
      Viglianti, and Thomas Weber<lb/><lb/><lb/><lb/></byline>
    <!--<docEdition>
      <hi rend="center">
        <table>
          <row>
            <cell>
              <graphic url="Images/hzonlineart.png"/>
            </cell>
            <cell>
              <graphic url="Images/dfg_logo_schwarz.png"/>
            </cell>
          </row>
        </table>
      </hi>
      <lb/>
      <lb/>
    </docEdition>
    <docImprint>This project is supported jointly by the National Endowment for the Humanities and
      the Deutsche Forschungsgemeinschaft. Any views, findings, conclusions or recommendations
      expressed in this publication do not necessarily reflect those of the National Endowment for
      the Humanities or the Deutsche Forschungsgemeinschaft.<lb/><lb/></docImprint>-->
    <!--<pb n="ii"/>-->
    <!--<docEdition><lb/><lb/>Music Encoding Initiative Guidelines, Version 3.0.0<lb/><lb/></docEdition>-->
    <docImprint>© by the Music Encoding Initiative (MEI) Council.<lb/>
      <pubPlace>Charlottesville and Detmold</pubPlace><docDate>2016</docDate></docImprint>
    <byline>
      <lb/><lb/>Licensed under the Educational Community License, Version 2.0 (the "License");
      you<lb/> may not use this file except in compliance with the License. You may obtain a
      copy<lb/> of the License at <ref target="http://creativecommons.org/licenses/by-nd/3.0/"
        >http://www.osedu.org/licenses/ECL-2.0</ref>.<lb/><lb/><lb/></byline>
  </titlePage>
  <div xml:id="frontTOC">
    <!--<head>Table of Contents</head>-->
    <divGen type="toc"/>
  </div>
  <!--<pb n="iii"/>-->

  <!--<pb n="iv"/>-->
  <div xml:id="frontAcknowledgments">
    <head>Acknowledgments</head>
    <p>Many institutions and individuals assisted in the preparation of these Guidelines and in the
      overall development of the Music Encoding Initiative (MEI) schema.</p>
    <p>Grateful acknowledgment is given to the following institutions for their generous
      contributions: the National Endowment for the Humanities (NEH) and the Deutsche
      Forschungsgemeinschaft (DFG) for their joint financial support of the MEI project, the
      Institute for Advanced Technology in the Humanities (IATH) at the University of Virginia and
      the Hochschule für Musik in Detmold for graciously hosting grant-funded meetings, the Center
      for Computer-Assisted Research in the Humanities (CCARH) at Stanford University for permission
      to make use of their large collection of encoded music, and the Distributed Digital Music
      Archives &amp; Libraries (DDMAL) Lab at McGill University and the Social Sciences and
      Humanities Research Council of Canada (SSHRC) for their continuing support of MEI-based
      research. The Akademie der Wissenschaften und der Literatur in Mainz deserves special
      recognition for being the official host of MEI and promoting its use through their granting
      activities. Finally, the editors wish to thank their own home institutions, the
      Musikwissenschaftliches Seminar Detmold/Paderborn and the University of Virginia Library, for
      providing financial support and environments that encourage experimentation.</p>
    <p>The Text Encoding Initiative is also owed a special debt of gratitude. In addition to
      providing much of the inspiration for MEI, the TEI organization supplied funding for the MEI
      Technical Group in its efforts to adopt ODD. The editors of these Guidelines are grateful for
      those of the TEI, which provided a stellar exemplar and from which we have <q>borrowed</q>
      shamelessly.</p>
    <p>The following individuals have provided much-appreciated commitments of time and energy to
      the development of MEI: Donald Byrd (Indiana University, Bloomington); Giuliano Di Bacco
      (Indiana University); Richard Freedman (Haverford College); Ichiro Fujinaga (McGill
      University, Montréal); Andrew Hankinson (McGill University); Erin Mayhood (University of
      Virginia Library); Stefan Morent (University of Tübingen); Daniel Pitti (Institute for
      Advanced Technology in the Humanities, University of Virginia); Laurent Pugin (RISM
      Switzerland); Daniel Röwenstrunk (Musikwissenschaftliches Seminar Detmold/Paderborn); Craig
      Sapp (Center for Computer-Assisted Research in the Humanities, Stanford University); Eleanor
      Selfridge-Field (Center for Computer-Assisted Research in the Humanities, Stanford); Christine
      Siegert (Beethoven-Haus, Bonn); Axel Teich Geertinger (Royal Danish Library, Copenhagen);
      Joachim Veit (Carl-Maria-von-Weber-Gesamtausgabe, Detmold); and Raffaele Viglianti (University
      of Maryland, College Park).</p>
    <p>Thanks to Bernhard R. Appel (Beethoven-Haus); J. Stephen Downie (University of Illinois,
      Urbana-Champaign); Oliver Huck (Universität Hamburg); Fotis Jannidis (Universität Würzburg);
      and Frans Wiering (University of Utrecht) for providing expertise on a wide range of topics
      related to music notation modelling.</p>
    <p>Also thanks to Syd Bauman and Terry Catapano for their invaluable problem-solving assistance
      during the development of the 2010 RNG schema. Thanks to the late Sebastian Rahtz and James
      Cummings of the Text Encoding Initiative (TEI) for their help with making ODD work with MEI,
      their assistance in more closely aligning MEI and TEI, and their quick responses to questions
      and Roma bug reports.</p>
  </div>
  <div xml:id="frontIntroduction">
    <head>Introduction</head>
    <p>This release of the Music Encoding Initiative (MEI) provides three major components:</p>
    <list type="bulleted">
      <item>formalized rules for recording the intellectual and physical characteristics of music
        notation documents so that the information contained in them may be searched, retrieved,
        displayed, and exchanged in a predictable and platform-independent manner;</item>
      <item>a data dictionary that documents the components of the MEI model; and</item>
      <item>best practices guidelines for the application of those rules.</item>
    </list>
    <p>Both the MEI rules and their documentation are expressed in the form of a One Document
      Does-it-all (ODD) document, a format developed by the Text Encoding Initiative (TEI). The MEI
      ODD document has been processed to create the MEI application guidelines, data dictionary, and
      accompanying schemas.</p>
    <p>The MEI Guidelines, which include the data dictionary, are intended to serve as a reference
      tool for music encoders. Through the use of natural-language definitions and examples, this
      document assists users of MEI in achieving effective and consistent markup. Despite
      translating XML and RNG terminology and concepts into more accessible language, it is still a
      technical one that presupposes a minimal understanding of XML and music notation. Novice
      encoders will need to supplement their use of the Guidelines by participating in discussions
      on the MEI-L list, attending introductory MEI workshops and training classes and by referring
      to other information sources.</p>
    <p>As a natural-language translation of the MEI conceptual model, the Guidelines convey
      information about the three principal tasks accomplished by the model. First, the model breaks
      down the content of music notation documents into data fields or categories of information
      called "elements". All of these elements are named, defined, and described in the data
      dictionary. Second, the data dictionary identifies and defines attributes associated with
      those elements. Attributes are characteristics or properties that further refine the element.
      Last, and perhaps most importantly, the data dictionary documents the structure of the MEI
      model by explaining the relationship between elements, specifying where the elements may be
      used and describing how they may be modified by attributes. While two of the basic purposes of
      MEI encompass the searching and display of encoded music notation documents in an electronic
      environment, nothing in the data dictionary specifically addresses their implementation.
      Searching and display are entirely dependent on software applications outside the scope of the
      MEI model.</p>
    <p>The MEI model contains only a few required elements, the majority are optional. Therefore,
      the amount of markup desired will vary from one situation to another depending on
      intellectual, technical, and temporal considerations. Creating encoded music notation
      documents for inclusion in union databases may also result in tagging requirements that are
      separate from those dictated by the model.</p>
    <p>Suggestions for new elements, revised descriptions, and more illustrative examples may be
      submitted to the MEI Working Group via the MEI discussion list at <ref
        target="mei-l@lists.uni-paderborn.de">mei-l@lists.uni-paderborn.de</ref>. The model and
      Guidelines will be updated periodically based on the feedback received from the users of
      MEI.</p>
  </div>
  <div xml:id="frontDesignPrinciples">
    <head>MEI Design Principles</head>
    <p>This section of the Guidelines defines principles and criteria for designing, developing, and
      maintaining an XML-based encoding scheme for music notation documents.</p>
    <list type="bulleted">
      <head>Definitions and Parameters</head>
      <item>A music notation document is one that contains music notation; that is, any one of a
        number of "visual analogues of musical sound, either as a record of sound heard or imagined,
        or as a set of visual instructions for performers." (Ian D. Bent, et al. "Notation." Grove
        Music Online. Oxford Music Online. 25 May 2010. &lt;<ref
          target="http://www.oxfordmusiconline.com/subscriber/article/grove/music/20114"
          >http://www.oxfordmusiconline.com/subscriber/article/grove/music/20114</ref>&gt;.)</item>
      <item>The encoding scheme permits both the creation of new music notation documents and the
        conversion of existing ones from print and other electronic formats. However, conversion of
        existing documents may require revisions in content or rearrangement of information.</item>
    </list>
    <list type="bulleted">
      <head>General Principles</head>
      <item>No prima facie distinction is made between a primary source of music notation, such as
        an autograph or published score, and a secondary source, such as a scholarly edition based
        on one or more primary sources. The tag set encompasses both, and the encoder must choose
        the elements and attributes most appropriate in each case.</item>
      <item>As an encoded representation of one or more music notation documents, an MEI file may be
        employed as a surrogate for the original materials.</item>
      <item>Although the encoding scheme does not define or prescribe intellectual content for music
        notation documents, it does define content designation and is intended to be used with
        available data content standards. MEI identifies the essential data elements within music
        notation documents and establishes codes and conventions necessary for capturing and
        distinguishing information within those elements for future action or manipulation. While
        there are a few elements that ought to appear in any MEI document, various intellectual,
        technical, and economic factors influence the level of detail of analysis and encoding
        actually undertaken. Taking this into consideration, the encoding scheme is designed with a
        minimum of required elements and allows for progressively more detailed levels of
        description as desired.</item>
      <item>The encoding scheme preserves and enhances the current functionality of existing music
        notation documents. It permits identification of document structures and content that
        support description, navigation, analysis, and online and print presentation.</item>
      <item>The encoding scheme is intended to facilitate interchange between notational tools. It
        aims to assist in the creation of more effective and consistent encoding, encourage the
        creation of cooperatively-created and widely available databases of music notation
        documents, and permit the reuse of encoded data for multiple output purposes. It will also
        ensure that machine-readable music notation documents will outlive changing hardware and
        software environments because they are based on a platform-independent standard.</item>
    </list>
    <list type="bulleted">
      <head>Structural Features</head>
      <item>The encoding scheme is based on eXtensible Markup Language (XML), a text-based format
        for representing structured information. It is expressed as a One Document Does-it-all (ODD)
        document, referred to as the "Music Encoding (MEI) Guidelines". For more information on ODD,
        please refer to TEI Guidelines chapter 22 (<ref
          target="http://www.tei-c.org/release/doc/tei-p5-doc/en/html/TD.html"
          >http://www.tei-c.org/release/doc/tei-p5-doc/en/html/TD.html</ref>), chapter 23 (<ref
          target="http://www.tei-c.org/release/doc/tei-p5-doc/en/html/USE.html"
          >http://www.tei-c.org/release/doc/tei-p5-doc/en/html/USE.html</ref>), and to the TEI's
        "Getting Started with P5 ODDs" document (<ref
          target="http://www.tei-c.org/Guidelines/Customization/odds.xml"
          >http://www.tei-c.org/Guidelines/Customization/odds.xml</ref>).</item>
      <item>Related or complementary standards, such as the Text Encoding Initiative (TEI)
        Guidelines for Electronic Text Encoding and Interchange (<ref
          target="http://www.tei-c.org/Guidelines/P5/">http://www.tei-c.org/Guidelines/P5/</ref>),
        the Encoded Archival Description (EAD) (<ref target="http://www.loc.gov/ead/"
          >http://www.loc.gov/ead/</ref>), MARC 21 Format for Bibliographic Data (<ref
          target="http://www.loc.gov/marc/bibliographic/ecbdhome.html"
          >http://www.loc.gov/marc/bibliographic/ecbdhome.html</ref>), existing notation encoding
        schemes, etc. have been consulted and employed as appropriate. For example, the data model
        includes a header that is comparable to the TEI header, and TEI and EAD naming conventions
        and tag structures have been used whenever feasible. However, while some feature names are
        similar, or even the same, it is important to recognize that MEI and TEI have different
        semantic scope. Obviously, a note element in MEI does not carry the same meaning as the
        element of the same name in TEI. Perhaps less obviously, a phrase in music notation is
        unrelated to a textual phrase.</item>
      <item>With respect to metadata, MEI recognizes the close relationship between the metadata
        content found in the MEI header and that of catalog records, authority records, and finding
        aids, and it provides for the use of an encoding equivalency attribute for MEI elements
        corresponding to fields in other metadata standards.</item>
      <item>To ensure broad international and multi-repertoire application of MEI, existing musical
        terminology was used in building the data model where practical. In addition, a method for
        localization of the data model's names has been provided. Finally, extensive use of
        attributes in the schema permits the refinement of element meanings with specific musical,
        geographic, or temporal contexts.</item>
    </list>
    <list type="bulleted">
      <head>Control and Maintenance</head>
      <item>Control and maintenance of the MEI model, schemas and documentation will be provided by
        a maintenance agency working in concert with the national and international music
        communities, assisted in an advisory capacity by other interested groups of users.</item>
    </list>
  </div>
  <div>
    <head>About Version 3.0.0</head>
    <p>The first major goal established for the 3.0.0 release was to refine the MEI object model;
      that is, identify and correct problems affecting MEI’s ability to capture data conveniently
      and effectively. While a few revisions modified the class structure of MEI without changing
      the resulting schema — mostly for schema construction convenience and "future proofing"
      reasons, but also to maintain compliance with recent changes to the TEI ODD framework — the
      usual outcome was the creation of both restrictions and extensions to the existing model.
      Extensions, such as allowing Scalable Vector Graphics (SVG) markup in certain contexts, adding
      new elements, and providing additional attributes on existing elements, presented no backward
      compatibility problems. Restrictions, however, such as separating data that had been recorded
      in a single attribute value into multiple attributes, moving elements from one location to
      another, tightening the definitions for datatypes, and adding new contextual constraints,
      resulted, as they usually do, in backward compatibility issues. To mitigate the effect of
      these compatibility problems, an XSLT stylesheet (mei21To30.xsl) was created that converts a
      file conforming to the previous version of MEI to one that validates against the
      mei-all_anyStart schema in this release. Every effort was made to thoroughly test this
      transformation. However, since the corpus of files available for testing was relatively small
      and its contents were somewhat homogenous, no guarantee is made that the conversion will be
      successful in all cases. Problems with the conversion reported to MEI-L or <ref
        target="contact@music-encoding.org">contact@music-encoding.org</ref> will be evaluated and
      addressed.</p>
    <p>Another major goal for this release was improvement of the Guidelines, including the
      reference section formerly known as the "Tag Library", now called the "Data Dictionary". The
      changes here included correction of typographical and grammatical errors, designating
      annotations previously given in XML comments as formal remarks, and reworking some parts of
      the document to make them more concise and (we hope) more informative.</p>
    <p>To see all of the changes made for this revision, please visit the Git repositories <ref
        target="https://github.com/music-encoding/music-encoding"
        >https://github.com/music-encoding/music-encoding</ref>, <ref
        target="https://github.com/music-encoding/encoding-tools"
        >https://github.com/music-encoding/encoding-tools</ref>, and <ref
        target="https://github.com/music-encoding/sample-encodings"
        >https://github.com/music-encoding/sample-encodings</ref>.</p>
    <p>The editors wish to thank everyone who participated in this process. Of course, errors are
      the sole responsibility of the editors.</p>
  </div>
</front>
